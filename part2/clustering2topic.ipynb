{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"f1f8a4455a674fd9b4cfdd0c6fac8f40","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Reviews Topic Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"375e6e252dda4cfaae30bd2e980acd75","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":5095,"execution_start":1697101614943,"source_hash":null},"outputs":[],"source":["# !pip install -q --disable-pip-version-check -r ../requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1cabb49e48d94261933e279d8a5473d7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":11,"execution_start":1697112230960,"source_hash":null},"outputs":[],"source":["# Randomization for seed reproduction\n","import random\n","\n","# Matrix operations\n","import numpy as np\n","\n","# Dataframes\n","import pandas as pd\n","\n","# Regular Expressions\n","import re\n","\n","# Import unidecode (to remove accents from words)\n","from unidecode import unidecode\n","\n","# Import wordcloud\n","from wordcloud import WordCloud\n","\n","# Sklearn Utilities\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import LatentDirichletAllocation\n","\n","# Visualize the information contained in a topic model\n","import pyLDAvis\n","from pyLDAvis import gensim as gensimvis\n","\n","import gensim\n","from gensim import corpora\n","\n","# Charts\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","\n","# SciKit Learn Utilities\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","# from sklearn.preprocessing import OneHotEncoder\n","# from sklearn.manifold import TSNE\n","# from sklearn.utils import shuffle\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.metrics import confusion_matrix\n","\n","# Natural Language Toolkit\n","import nltk\n","from nltk.tokenize import word_tokenize\n","\n","# Language Detection\n","from langdetect import detect\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set a random seed for reproducibility\n","random_seed = 10\n","np.random.seed(random_seed)\n","random.seed(random_seed)"]},{"cell_type":"markdown","metadata":{"cell_id":"d23c2c7731404757b70505b1f8b16d57","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["---\n","## 1. Displaying initial data"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2ba34335ad1d4ad1a42537ba8b88be0e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":209,"execution_start":1697111888894,"source_hash":null},"outputs":[],"source":["reviews_df = pd.read_csv('../data/Big_AHR.csv', index_col=0)\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"2264603e20474efebdb9f499308854f6","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["Obtain an example from the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"bfeb6a5ea8854650a2dc352c811fa0f4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":29,"execution_start":1697111891334,"source_hash":null},"outputs":[],"source":["def get_one_sample_with_columns(df, id=0):\n","    return list(zip(list(df.columns), list(df.iloc[id])))"]},{"cell_type":"markdown","metadata":{"cell_id":"a6fe4ceeb02a416889886ef574c4e1dd","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["Display the rating and the sentiment associated to the review:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c25421ca44674f9c997b420bdd8953f3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":15,"execution_start":1697111893066,"source_hash":null},"outputs":[],"source":["def display_ratings(df):\n","    rating = df['rating'].value_counts()\n","\n","    fig = px.bar(\n","        x=rating.index,\n","        y=rating.values,\n","        labels={'x': 'Rating', 'y': 'Count'},\n","        title='Count of Each Unique Rating'\n","    )\n","\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0819170109e74a16a5ee4ed5ac92841f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":15,"execution_start":1697111894668,"source_hash":null},"outputs":[],"source":["def display_review_sentiment(df):\n","    SENTIMENT_CONVERSION = { 0: \"Negative\", 1: \"Positive\", 3: \"Neutral\" }\n","\n","    sentiment_column = df['label'].value_counts().sort_index()\n","\n","    fig = px.bar(\n","        # Convert numerical x-axis labels to string labels\n","        x=[SENTIMENT_CONVERSION[label] for label in sentiment_column.index],\n","        y=sentiment_column.values,\n","        labels={'x': 'Sentiment', 'y': 'Count'},\n","        title='Count of Each Unique Sentiment'\n","    )\n","\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ccf5bbdadd874d3bb7c37452f8ed1704","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":312,"execution_start":1697111895516,"source_hash":null},"outputs":[],"source":["# display_ratings(reviews_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8eef0297e83b473eaa67ad3fe178b734","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":303,"execution_start":1697111898016,"source_hash":null},"outputs":[],"source":["# display_review_sentiment(reviews_df)"]},{"cell_type":"markdown","metadata":{"cell_id":"590d5570663c4f71b3b1b9b4fc29d388","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["As we can see, the dataset is completely unbalanced. There are almost 10x of 5-star ratings that 2-star ratings."]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 2. Text Preprocessing\n","We will discard everything but the review *review_text* as it is the only useful for the topic modelling process"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get every column and drop everything except for review_text\n","reviews_df = reviews_df.drop(reviews_df.columns.difference(['review_text']), axis=1)\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"4de59522e5cc4a82b21b8933088156c0","deepnote_cell_type":"text-cell-h3","formattedRanges":[]},"source":["### 2.1. Removing NaN and missing values"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"372e3130231a4f5f8fbd77d572b87205","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":16,"execution_start":1697111905509,"source_hash":null},"outputs":[],"source":["def has_nan_or_missing_values(df):\n","    # Check for NaN values\n","    nan_check = df.isna().any()\n","\n","    # Check for empty values (assuming empty strings)\n","    empty_check = (df == '').any()\n","\n","    # Combine the results to check for both NaN and empty values\n","    has_nan_or_empty = nan_check | empty_check\n","\n","    print(has_nan_or_empty)\n","    print(f\"Number of samples: {df.shape[0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ce8a168213034556901cce3be99a29c9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":45,"execution_start":1697111907252,"source_hash":null},"outputs":[],"source":["has_nan_or_missing_values(reviews_df)"]},{"cell_type":"markdown","metadata":{"cell_id":"2b48b374c148436bb211cc9300c0de64","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["✅ Removing the NaN values resulted on also removing the NaN and missing values from the hotel attribute."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"542a57163ddf406fb14d21ec03573032","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":30,"execution_start":1697111927057,"source_hash":null},"outputs":[],"source":["get_one_sample_with_columns(reviews_df)"]},{"cell_type":"markdown","metadata":{"cell_id":"3fc753785fe5453e8bd215684834ccdf","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["Obtain more information about the dataframe:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1184244c0af64e0591ea05c937bb7050","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":33,"execution_start":1697111929073,"source_hash":null},"outputs":[],"source":["reviews_df.info()"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2. Text Preprocessing\n","We will only keep the Spanish reviews with the langdetect library. Otherwise, the TF_IDF matrix will be too sparse."]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.1. Filter Spanish reviews"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove all non-Spanish reviews\n","# reviews_df = reviews_df[reviews_df['review_text'].apply(lambda x: detect(x) == 'es')]\n","# reviews_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reset the indeces\n","# reviews_df = reviews_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the dataframe to a CSV file\n","# reviews_df.to_csv('../data/Topic_Modelling_Big_AHR_Spanish.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import the CSV file\n","reviews_df = pd.read_csv('../data/Topic_Modelling_Big_AHR_Spanish.csv', index_col=0)\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.2. Remove punctuation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove punctuation using regular expressions\n","# We just keep the words and spaces\n","reviews_df['review_text'] = reviews_df['review_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.3. Transform text to lowercase"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Transform all words to lowercase (consistency)\n","reviews_df['review_text'] = reviews_df['review_text'].apply(lambda x: x.lower())\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.4. Remove Stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize stopwords\n","stop_words = set(stopwords.words('spanish'))\n","\n","# Define the text preprocessing function\n","def remove_stop_words(text):\n","    # Remove stop words\n","    words = text.split()  # Split text into words\n","    words = [word for word in words if word not in stop_words]  # Remove stop words\n","    return ' '.join(words)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# preprocess the df\n","reviews_df['review_text'] = reviews_df['review_text'].apply(remove_stop_words)\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.5. Remove non-spanish words\n","Delete not spanish words or misspelled words that lead to errors and confusion\n","##### 3 hours to execute, please don't. Instead use the file Reduced_Topic_Modelling_Big_AHR_Spanish.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from concurrent.futures import ThreadPoolExecutor\n","# from spellchecker import SpellChecker\n","\n","# spanish = SpellChecker(language='es')\n","\n","# def fix_non_words(text: str, column_n) -> str:\n","#     corrected_words = [spanish.correction(word) if spanish.correction(word) else '' for word in text.split()]\n","#     # print(f'{text} -> {corrected_words}')\n","#     return ' '.join(corrected_words)\n","\n","# # Define the number of threads you want to use\n","# num_threads = 12\n","\n","# # Create a ThreadPoolExecutor with the specified number of threads\n","# with ThreadPoolExecutor(max_workers=num_threads) as executor:\n","#     # Use the executor to apply the fix_non_words function to each element in the 'review_text' column concurrently\n","#     reviews_df['review_text'] = list(executor.map(fix_non_words, reviews_df['review_text'], reviews_df.index))\n","\n","\n","# save the dataframe to a CSV file\n","# reviews_df.to_csv('../data/Reduced_Topic_Modelling_Big_AHR_Spanish.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reviews_df = pd.read_csv('../data/Reduced_Topic_Modelling_Big_AHR_Spanish.csv', index_col=0)\n","\n","reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.4. Remove accents - deprecated\n","With the application of the spellchecker, there is no need to remove accents.\n","\n","As we are processing a latin language, is important to strip accents and special characters in order to generalize better"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reviews_df['review_text'] = reviews_df['review_text'].apply(unidecode)\n","\n","# reviews_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### 2.2.5. Remove single and pair character words\n","Problem detected in the exploratory analysis. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reviews_df['review_text'] = reviews_df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 2]))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 3. Exploratory analysis\n","Show wordcloud to visualize possible problems in the data"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1. Wordcloud"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_wordcloud(df, column_name, name='wordcloud', random_seed=None):\n","    # Join all reviews into a single string\n","    all_reviews = \" \".join(df[column_name])\n","\n","    # Generate the word cloud with the specified random seed\n","    wordcloud = WordCloud(\n","        width=1600, height=800, max_font_size=200, background_color=\"white\", colormap=\"magma\",\n","        random_state=random_seed\n","    ).generate(all_reviews)\n","\n","    # Create a Matplotlib figure and axis\n","    fig, ax = plt.subplots(figsize=(16, 8), facecolor=\"white\")\n","\n","    # Add the title\n","    plt.title('Word Cloud for Reviews', fontsize=24, pad=20, color='black', fontweight='medium')\n","\n","    # Display the word cloud\n","    ax.imshow(wordcloud, interpolation=\"bilinear\")\n","    ax.axis(\"off\")\n","\n","    # Save the generated image\n","    plt.savefig(f'../images/{name}.png')\n","    \n","    # Show the generated image\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# generate_wordcloud(reviews_df, \"review_text\", \"wordcloud_pre_manual\", random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2. Manual review"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Delete words that may be due to errors\n","wrong_words = ['ma', 'asi', 'una', 'aunque', 'además', 'hace', 'etc', 'q', 'pue', 'si', 'tan', 'sido']\n","reviews_df['review_text'] = reviews_df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in wrong_words]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generate_wordcloud(reviews_df, \"review_text\", 'wordcloud_post_manual', random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 4. Latent Dirichlet Allocation"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1. Tokenize words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the resources for NLTK spanish tokenizer\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenize the reviews if they are not already tokenized\n","tokens_df = reviews_df.copy()\n","\n","tokens_df['review_text'] = tokens_df['review_text'].apply(lambda x: word_tokenize(x, language='spanish') if isinstance(x, str) else x)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2. Corpus & Dictionaries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenize the reviews if they are not already tokenized\n","tokens_df[\"review_text\"] = tokens_df[\"review_text\"].apply(\n","    lambda x: word_tokenize(x, language=\"spanish\") if isinstance(x, str) else x\n",")\n","\n","# Create Dictionary\n","id2word = corpora.Dictionary(tokens_df[\"review_text\"])\n","\n","# Create Corpus\n","texts = tokens_df[\"review_text\"]\n","\n","# Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]\n","\n","# View\n","print(corpus[:1][0][:30])"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 5. Latent Dirichlet Allocation Training"]},{"cell_type":"markdown","metadata":{},"source":["### 5.1. Output functions"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.1.1. Topic Wordclouds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_topic_wordclouds(lda_model, name, num_topics):\n","    for topic_num in range(num_topics):\n","        # Get the words associated with the topic\n","        topic_words = lda_model.show_topic(topic_num, topn=30)\n","        # Create a dictionary of topic words and their probabilities\n","        topic_word_dict = {word: prob for word, prob in topic_words}\n","        \n","        # Generate a word cloud for the topic\n","        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(topic_word_dict)\n","        \n","        # Display the word cloud for the topic\n","        plt.figure(figsize=(8, 4))\n","        plt.imshow(wordcloud, interpolation='bilinear')\n","        plt.title(f'Topic {topic_num + 1} Word Cloud')\n","        plt.axis(\"off\")\n","        plt.savefig(f'../images/topic_{name}_{topic_num + 1}_wordcloud.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.colors as mcolors\n","\n","\n","def create_multiple_topic_wordclouds(\n","    lda_model, num_topics, width=2500, height=1800, max_words=20\n","):\n","    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n","\n","    cloud = WordCloud(\n","        background_color=\"white\",\n","        width=width,\n","        height=height,\n","        max_words=max_words,\n","        colormap=\"tab10\",\n","    )\n","\n","    topics = lda_model.show_topics(formatted=False)\n","\n","    # Calculate the number of rows for subplots\n","    num_rows = (num_topics + 1) // 2\n","\n","    # Create subplots\n","    fig, axes = plt.subplots(2, 5, figsize=(15, 15), sharex=True, sharey=True)\n","\n","    for i, ax in enumerate(axes.flatten()):\n","        if i < num_topics:\n","            topic_words = dict(topics[i][1])\n","            cloud.generate_from_frequencies(topic_words, max_font_size=300)\n","            ax.imshow(cloud)\n","            ax.set_title(\"Topic \" + str(i), fontdict=dict(size=16))\n","            ax.axis(\"off\")\n","        else:\n","            # Remove extra subplots if there are more than 'num_topics'\n","            fig.delaxes(ax)\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.1.2. Intertopic Distance Map"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def intertopic_distance(lda_model, name, corpus):\n","  pyLDAvis.enable_notebook()\n","  vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n","  pyLDAvis.save_html(vis, f'../images/{name}.html')\n","  return vis"]},{"cell_type":"markdown","metadata":{},"source":["### 5.2. LDA Model 1. 10 Topics"]},{"cell_type":"markdown","metadata":{},"source":["Better to use gensim library rather than scykitlearn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# number of topics\n","num_topics = 10\n","\n","# Build LDA model\n","lda_model1 = gensim.models.LdaMulticore(corpus=corpus,\n","                                       id2word=id2word,\n","                                       num_topics=num_topics,\n","                                       random_state=100,)\n","# Print the Keyword in the 10 topics\n","print(lda_model1.print_topics())\n","doc_lda = lda_model1[corpus]"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.2.1. Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["create_topic_wordclouds(lda_model1, 'lda_model1', num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create_multiple_topic_wordclouds(lda_model1, num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intertopic_distance(lda_model1, 'lda_model1', corpus)"]},{"cell_type":"markdown","metadata":{},"source":["### 5.3. LDA Model 2. 10 Topics with Parameter Tunning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# number of topics\n","num_topics = 10\n","\n","# Define LDA model parameters\n","lda_params = {\n","    'corpus': corpus,\n","    'id2word': id2word,\n","    'num_topics': num_topics,\n","    'random_state': 100,  # Reproducibility seed\n","    'passes': 30,  # Increase the number of passes for better convergence\n","    'eta': 'auto',  # Automatically set eta\n","}\n","\n","# Build LDA model\n","lda_model2 = gensim.models.LdaMulticore(**lda_params)\n","\n","# Print the Keyword in the 10 topics\n","print(lda_model2.print_topics())\n","doc_lda = lda_model2[corpus]"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.3.1. Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["create_topic_wordclouds(lda_model2, 'lda_model2', num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create_multiple_topic_wordclouds(lda_model2, num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intertopic_distance(lda_model2, 'lda_model2', corpus)"]},{"cell_type":"markdown","metadata":{},"source":["### 5.4. LDA Model 3. 4 Topics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# number of topics\n","num_topics = 4\n","\n","# Build LDA model\n","lda_model3 = gensim.models.LdaMulticore(corpus=corpus,\n","                                       id2word=id2word,\n","                                       num_topics=num_topics,\n","                                       random_state=100,)\n","\n","# Print the Keyword in the 10 topics\n","print(lda_model3.print_topics())\n","doc_lda = lda_model3[corpus]"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.4.1. Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["create_topic_wordclouds(lda_model3, 'lda_model3', num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create_multiple_topic_wordclouds(lda_model3, num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intertopic_distance(lda_model3, 'lda_model3', corpus)"]},{"cell_type":"markdown","metadata":{},"source":["### 5.5. LDA Model 4. 4 Topics with Parameter Tunning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# number of topics\n","num_topics = 4\n","\n","# Define LDA model parameters\n","lda_params = {\n","    'corpus': corpus,\n","    'id2word': id2word,\n","    'num_topics': num_topics,\n","    'random_state': 100,  # Reproducibility seed\n","    'passes': 30,  # Increase the number of passes for better convergence\n","    'eta': 'auto',  # Automatically set eta\n","}\n","\n","# Build LDA model\n","lda_model4 = gensim.models.LdaMulticore(**lda_params)\n","\n","# Print the Keyword in the 10 topics\n","print(lda_model4.print_topics())\n","doc_lda = lda_model4[corpus]"]},{"cell_type":"markdown","metadata":{},"source":["#### 5.2.1. Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["create_topic_wordclouds(lda_model4, 'lda_model4', num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create_multiple_topic_wordclouds(lda_model4, num_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intertopic_distance(lda_model4, 'lda_model4', corpus)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## 6. Evaluation\n","\n","**Coherence Score**: Coherence score quantifies the interpretability and consistency of topics in a topic model; higher coherence scores indicate more meaningful and coherent topics within the model.\n","\n","**Perplexity**: Perplexity is a measure of how well a probabilistic model, such as a language model or a topic model, predicts a given dataset; lower perplexity values indicate that the model better captures the data's underlying patterns and is more confident in its predictions."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from gensim.models import CoherenceModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate Model 1\n","coherence_model1 = CoherenceModel(model=lda_model1, texts=texts, dictionary=id2word, coherence='c_v')\n","coherence1 = coherence_model1.get_coherence()\n","perplexity1 = lda_model1.log_perplexity(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate Model 2\n","coherence_model2 = CoherenceModel(model=lda_model2, texts=texts, dictionary=id2word, coherence='c_v')\n","coherence2 = coherence_model2.get_coherence()\n","perplexity2 = lda_model2.log_perplexity(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate Model 3\n","coherence_model3 = CoherenceModel(model=lda_model3, texts=texts, dictionary=id2word, coherence='c_v')\n","coherence3 = coherence_model3.get_coherence()\n","perplexity3 = lda_model3.log_perplexity(corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate Model 4\n","coherence_model4 = CoherenceModel(model=lda_model4, texts=texts, dictionary=id2word, coherence='c_v')\n","coherence4 = coherence_model4.get_coherence()\n","perplexity4 = lda_model4.log_perplexity(corpus)"]},{"cell_type":"markdown","metadata":{},"source":["### 6.1. Coherence scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Coherence scores\n","print(f\"Coherence Score for Model 1: {coherence1}\")\n","print(f\"Coherence Score for Model 2: {coherence2}\")\n","print(f\"Coherence Score for Model 3: {coherence3}\")\n","print(f\"Coherence Score for Model 4: {coherence4}\")"]},{"cell_type":"markdown","metadata":{},"source":["### 6.2. Perplexity scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Perplexity scores\n","print(f\"Perplexity for Model 1: {perplexity1}\")\n","print(f\"Perplexity for Model 2: {perplexity2}\")\n","print(f\"Perplexity for Model 3: {perplexity3}\")\n","print(f\"Perplexity for Model 4: {perplexity4}\")"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c29b5edc0871474797f6b9e36542939e","kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
